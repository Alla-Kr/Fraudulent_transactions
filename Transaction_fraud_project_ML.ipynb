{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting model evalution statistics\n",
    "model_evalution_df = pd.DataFrame(columns=['Model Name', 'Training Score', 'Testing Score', 'Accuracy', 'F1 Score', 'Precision', 'Recall'])\n",
    "\n",
    "def add_model_evalution_stat(model_name, model, X_train, X_test, y_train, y_test, y_train_pred, y_test_pred, model_evalution_df):\n",
    "    \"\"\"Function for adding model evalution statistics to DataFrame\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Model name\n",
    "        model (object): Object of fitted model\n",
    "        X_train (DataFrame): Train dataset\n",
    "        X_test (DataFrame): Test dataset\n",
    "        y_train (DataFrame): Train labels\n",
    "        y_test (DataFrame): Test labels\n",
    "        y_train_pred (DataFrame): Predicted train labels\n",
    "        y_test_pred (DataFrame): Predicted test labels\n",
    "        model_evalution_df (DataFrame): DataFrame with evalution statistics\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with added statistics\n",
    "    \"\"\"\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "    f1_score = metrics.f1_score(y_test, y_test_pred, average='weighted')\n",
    "    precision = metrics.precision_score(y_test, y_test_pred)\n",
    "    recall = metrics.recall_score(y_test, y_test_pred)\n",
    "    model_evalutions_stats = [model_name, train_score, test_score, accuracy, f1_score, precision, recall]\n",
    "    model_evalution_dict = {model_evalution_df.columns[i]:model_evalutions_stats[i] for i in range(len(model_evalutions_stats))}\n",
    "    model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n",
    "    return model_evalution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_processed.drop(['fraud'], axis=1)\n",
    "y = df_processed['fraud']\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 42, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44137, 75)\n",
      "(102986, 75)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's work on creating a baseline__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a not so simple model and experiment with a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall: 0.35\n",
      "Train f1: 0.52\n",
      "Test recall: 0.27\n",
      "\n",
      "Test f1: 0.43\n"
     ]
    }
   ],
   "source": [
    "model_rf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    criterion='gini',\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    random_state=13\n",
    ")\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_train_pred = model_rf.predict(X_train)\n",
    "print('Train recall: {:.2f}'.format(metrics.recall_score(y_train, y_train_pred)))\n",
    "print('Train f1: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = model_rf.predict(X_test)\n",
    "print('Test recall: {:.2f}'.format(metrics.recall_score(y_test, y_test_pred)))\n",
    "print()\n",
    "print('Test f1: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make another basic model using df_processed_1 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us recall that at the stage of reconnaissance analysis we identified two correlated features and the df_processed_1 data contains one of them - days_since_last_logon, the df_processed data contains the other - group_days_since_last_logon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = df_processed_1.drop(['fraud'], axis=1)\n",
    "y_1 = df_processed_1['fraud']\n",
    " \n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, stratify=y, random_state = 42, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall: 0.40\n",
      "Train f1: 0.57\n",
      "Test recall: 0.34\n",
      "\n",
      "Test f1: 0.50\n"
     ]
    }
   ],
   "source": [
    "model_rf_1 = ensemble.RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    criterion='gini',\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    random_state=13\n",
    ")\n",
    "\n",
    "model_rf_1.fit(X_train_1, y_train_1)\n",
    "y_train_pred_1 = model_rf_1.predict(X_train_1)\n",
    "print('Train recall: {:.2f}'.format(metrics.recall_score(y_train_1, y_train_pred_1)))\n",
    "print('Train f1: {:.2f}'.format(metrics.f1_score(y_train_1, y_train_pred_1)))\n",
    "y_test_pred_1 = model_rf_1.predict(X_test_1)\n",
    "print('Test recall: {:.2f}'.format(metrics.recall_score(y_test_1, y_test_pred_1)))\n",
    "print()\n",
    "print('Test f1: {:.2f}'.format(metrics.f1_score(y_test_1, y_test_pred_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the most suitable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [10 11] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Feature: account_age_days, Score: 1815.3937850020484\n",
      "2. Feature: transaction_amt, Score: 1580.3951123068073\n",
      "3. Feature: transaction_adj_amt, Score: 15841.400495512637\n",
      "4. Feature: historic_velocity, Score: 0.11054434179965776\n",
      "5. Feature: days_since_last_logon, Score: 0.011331690301879013\n",
      "6. Feature: inital_amount, Score: 0.07478969604828632\n",
      "7. Feature: year, Score: 1.68893844353431\n",
      "8. Feature: month, Score: 6.420333424866\n",
      "9. Feature: hour, Score: 0.46716840820262706\n",
      "10. Feature: day_of_week, Score: 2.062373288970358\n",
      "11. Feature: billing_country_USA, Score: nan\n",
      "12. Feature: billing_country, Score: nan\n",
      "13. Feature: country_match, Score: 0.2409949941203818\n",
      "14. Feature: black_list, Score: 7139.093656679107\n",
      "15. Feature: currency_cad, Score: 73.15444956692386\n",
      "16. Feature: currency_eur, Score: 124.0974935911433\n",
      "17. Feature: currency_usd, Score: 18.91011953887548\n",
      "18. Feature: browser_0, Score: 0.012919131174316766\n",
      "19. Feature: browser_1, Score: 0.012919131124584749\n",
      "20. Feature: billing_city_0, Score: 0.19159890162544557\n",
      "21. Feature: billing_city_1, Score: 4.204832212417353\n",
      "22. Feature: billing_city_2, Score: 0.059714881400947356\n",
      "23. Feature: billing_city_3, Score: 0.3767711924768905\n",
      "24. Feature: billing_city_4, Score: 0.137642761933745\n",
      "25. Feature: billing_city_5, Score: 0.09167361552846913\n",
      "26. Feature: billing_city_6, Score: 1.1440754249890612\n",
      "27. Feature: billing_city_7, Score: 0.36523744990728024\n",
      "28. Feature: billing_city_8, Score: 0.19596354476735917\n",
      "29. Feature: billing_city_9, Score: 0.06294527684851821\n",
      "30. Feature: billing_city_10, Score: 1.5833344465080914\n",
      "31. Feature: billing_city_11, Score: 0.7545211471264799\n",
      "32. Feature: billing_city_12, Score: 4.006639816670334\n",
      "33. Feature: billing_city_13, Score: 0.01307359283505403\n",
      "34. Feature: billing_state_0, Score: 5.2311236518766\n",
      "35. Feature: billing_state_1, Score: 1.3429279363223243\n",
      "36. Feature: billing_state_2, Score: 2.770402057482809\n",
      "37. Feature: billing_state_3, Score: 0.009698389718159417\n",
      "38. Feature: billing_state_4, Score: 0.5659067480707117\n",
      "39. Feature: billing_state_5, Score: 0.14942166287930247\n",
      "40. Feature: signature_image_0, Score: 426.0422273248141\n",
      "41. Feature: signature_image_1, Score: 72.19297111471887\n",
      "42. Feature: signature_image_2, Score: 22.226640307191758\n",
      "43. Feature: signature_image_3, Score: 0.1450700883218752\n",
      "44. Feature: signature_image_4, Score: 10.52171598869836\n",
      "45. Feature: transaction_type_0, Score: 2.0422455765276477\n",
      "46. Feature: transaction_type_1, Score: 68.59332485365327\n",
      "47. Feature: transaction_type_2, Score: 15.739280258487522\n",
      "48. Feature: transaction_type_3, Score: 43.82240170993438\n",
      "49. Feature: transaction_type_4, Score: 2.4642025222774775\n",
      "50. Feature: transaction_env_0, Score: 2314.88785663374\n",
      "51. Feature: transaction_env_1, Score: 169.43474923428028\n",
      "52. Feature: transaction_env_2, Score: 24.294341631527626\n",
      "53. Feature: transaction_env_3, Score: 329.73837637203115\n",
      "54. Feature: transaction_env_4, Score: 46.65644185105531\n",
      "55. Feature: tranaction_initiate_0, Score: 0.1925103363843959\n",
      "56. Feature: tranaction_initiate_1, Score: 0.9892192124399597\n",
      "57. Feature: tranaction_initiate_2, Score: 0.22248085869058287\n",
      "58. Feature: tranaction_initiate_3, Score: 0.3666522550704098\n",
      "59. Feature: tranaction_initiate_4, Score: 0.7533380308669692\n",
      "60. Feature: ip_country_0, Score: 0.03863189107964994\n",
      "61. Feature: ip_country_1, Score: 1.194552970298918\n",
      "62. Feature: ip_country_2, Score: 0.04579792378633271\n",
      "63. Feature: ip_country_3, Score: 0.03777855418732039\n",
      "64. Feature: ip_country_4, Score: 0.22733189483054592\n",
      "65. Feature: ip_country_5, Score: 0.13400087491646\n",
      "66. Feature: ip_country_6, Score: 0.689211564516536\n",
      "67. Feature: ip_country_7, Score: 0.7910398626496256\n",
      "68. Feature: locale_country_0, Score: 0.9448622676470295\n",
      "69. Feature: locale_country_1, Score: 0.9586838734723537\n",
      "70. Feature: locale_country_2, Score: 2.612701536321907\n",
      "71. Feature: locale_country_3, Score: 0.01026511521847313\n",
      "72. Feature: locale_country_4, Score: 1.8709987855863333\n",
      "73. Feature: locale_country_5, Score: 0.6983254879964587\n",
      "74. Feature: locale_country_6, Score: 0.002225396056467101\n",
      "75. Feature: locale_country_7, Score: 0.5292721150673527\n"
     ]
    }
   ],
   "source": [
    "# using SelectKBest we will select the most suitable features\n",
    "best_f = SelectKBest(k='all')\n",
    "best_f.fit(X_train, y_train)\n",
    "X_train_fs = best_f.transform(X_train)\n",
    "X_test_fs = best_f.transform(X_test)\n",
    "\n",
    "# display selected features and their scores\n",
    "selected_features = best_f.get_support(indices=True)\n",
    "feature_scores = best_f.scores_[selected_features]\n",
    "for i, (feature, score) in enumerate(zip(X_train.columns[selected_features], feature_scores), 1):\n",
    "    print(f\"{i}. Feature: {feature}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SelectKBest, we will select 25 features that are best for predicting the target variable. We implement selection using a training sample using the chi2 parameter\n",
    "\n",
    "We indicate the characteristics that are included in the selected list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['account_age_days', 'transaction_amt', 'transaction_adj_amt',\n",
      "       'historic_velocity', 'inital_amount', 'month', 'day_of_week',\n",
      "       'black_list', 'currency_cad', 'currency_eur', 'currency_usd',\n",
      "       'billing_city_1', 'billing_state_0', 'signature_image_0',\n",
      "       'signature_image_1', 'signature_image_2', 'signature_image_4',\n",
      "       'transaction_type_1', 'transaction_type_2', 'transaction_type_3',\n",
      "       'transaction_env_0', 'transaction_env_1', 'transaction_env_2',\n",
      "       'transaction_env_3', 'transaction_env_4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Create a SelectKBest object with score_func=chi2 and k=25\n",
    "best_features_selector = SelectKBest(score_func=chi2, k=25)\n",
    "\n",
    "# We train SelectKBest using training data\n",
    "X_train_selected = best_features_selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Displaying selected features\n",
    "selected_feature_indices = best_features_selector.get_support(indices=True)\n",
    "selected_features = X.columns[selected_feature_indices]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_selected\n",
    "X_test = X_test[['account_age_days', 'transaction_amt', 'transaction_adj_amt',\n",
    "       'historic_velocity', 'inital_amount', 'month', 'day_of_week',\n",
    "       'black_list', 'currency_cad', 'currency_eur', 'currency_usd',\n",
    "       'billing_city_1', 'billing_state_0', 'signature_image_0',\n",
    "       'signature_image_1', 'signature_image_2', 'signature_image_4',\n",
    "       'transaction_type_1', 'transaction_type_2', 'transaction_type_3',\n",
    "       'transaction_env_0', 'transaction_env_1', 'transaction_env_2',\n",
    "       'transaction_env_3', 'transaction_env_4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# normalize the data using minmaxscaler\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have selected the features, let's see how random forest works on them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fill out the table for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     41732\n",
      "           1       0.81      0.55      0.65      2405\n",
      "\n",
      "    accuracy                           0.97     44137\n",
      "   macro avg       0.89      0.77      0.82     44137\n",
      "weighted avg       0.97      0.97      0.97     44137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model Name  Training Score  Testing Score  \\\n",
       "0  LogisticRegression / Imbalanced data        0.969423       0.968484   \n",
       "\n",
       "   Accuracy  F1 Score  Precision    Recall  \n",
       "0  0.968484  0.965576   0.812192  0.548441  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model with random under sampled data\n",
    "model_name = 'LogisticRegression / Imbalanced data'\n",
    "lr = linear_model.LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "lr = lr.fit(X_train_scaled, y_train)\n",
    "y_train_pred = lr.predict(X_train_scaled)\n",
    "y_test_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test, y_test_pred)}')\n",
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, lr, X_train_scaled, X_test_scaled, y_train, y_test, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name2 = 'Baseline - RandomForestClassifier / Imbalanced data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall train 0.74\n",
      "Recall test 0.72\n"
     ]
    }
   ],
   "source": [
    "random_forest_base = ensemble.RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    criterion='gini',\n",
    "    min_samples_leaf=20,\n",
    "    random_state=42\n",
    ")\n",
    "random_forest_base.fit(X_train_scaled, y_train)\n",
    "y_train_pred_rf = random_forest_base.predict(X_train_scaled)\n",
    "y_test_pred_rf = random_forest_base.predict(X_test_scaled)\n",
    "# Calculation of the RMSLE metric on training and validation sets\n",
    "print('Recall train', round(np.sqrt(metrics.recall_score(y_train, y_train_pred_rf)), 2))\n",
    "print('Recall test', round(np.sqrt(metrics.recall_score(y_test, y_test_pred_rf)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We will take this model as the base one and compare further variations with the base one__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name2, random_forest_base, X_train_scaled, X_test_scaled, y_train, y_test, y_train_pred_rf, y_test_pred_rf, model_evalution_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Training Score  \\\n",
       "0               LogisticRegression / Imbalanced data        0.969423   \n",
       "1  Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "\n",
       "   Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0       0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1       0.970750  0.970750  0.967033   0.899570  0.521414  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name3 = 'Stacking / Imbalanced data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     41732\n",
      "           1       0.88      0.69      0.77      2405\n",
      "\n",
      "    accuracy                           0.98     44137\n",
      "   macro avg       0.93      0.84      0.88     44137\n",
      "weighted avg       0.98      0.98      0.98     44137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We create a list of tuples of the form: (model name, model)\n",
    "estimators = [\n",
    "    ('dt', tree.DecisionTreeClassifier(\n",
    "        criterion='entropy',\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "        )),\n",
    "    ('gb', ensemble.GradientBoostingClassifier(\n",
    "        min_samples_leaf=5,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "        )),\n",
    "    ('rf', ensemble.RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "        ))\n",
    "]\n",
    "\n",
    "# Create an object of the stacking class\n",
    "\n",
    "clf = ensemble.StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=ensemble.RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "y_train_pred_clf = clf.predict(X_train_scaled)\n",
    "y_test_pred_clf = clf.predict(X_test_scaled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test, y_test_pred_clf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Training Score  \\\n",
       "0               LogisticRegression / Imbalanced data        0.969423   \n",
       "1  Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                         Stacking / Imbalanced data        0.980939   \n",
       "\n",
       "   Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0       0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1       0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2       0.977592  0.977592  0.976290   0.876596  0.685239  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name3, clf, X_train_scaled, X_test_scaled, y_train, y_test, y_train_pred_rf, y_test_pred_clf, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to train a model on 45 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_45f, X_test_45f, y_train45f, y_test45f = train_test_split(X, y, stratify=y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['account_age_days', 'transaction_amt', 'transaction_adj_amt',\n",
      "       'historic_velocity', 'inital_amount', 'month', 'hour', 'day_of_week',\n",
      "       'black_list', 'currency_cad', 'currency_eur', 'currency_usd',\n",
      "       'billing_city_1', 'billing_city_6', 'billing_city_10',\n",
      "       'billing_city_11', 'billing_city_12', 'billing_state_0',\n",
      "       'billing_state_1', 'billing_state_2', 'billing_state_4',\n",
      "       'signature_image_0', 'signature_image_1', 'signature_image_2',\n",
      "       'signature_image_4', 'transaction_type_0', 'transaction_type_1',\n",
      "       'transaction_type_2', 'transaction_type_3', 'transaction_type_4',\n",
      "       'transaction_env_0', 'transaction_env_1', 'transaction_env_2',\n",
      "       'transaction_env_3', 'transaction_env_4', 'tranaction_initiate_1',\n",
      "       'tranaction_initiate_4', 'ip_country_1', 'ip_country_7',\n",
      "       'locale_country_0', 'locale_country_1', 'locale_country_2',\n",
      "       'locale_country_4', 'locale_country_5', 'locale_country_7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a SelectKBest object with score_func=chi2 and k=45\n",
    "best_features_selector = SelectKBest(score_func=chi2, k=45)\n",
    "\n",
    "# We train SelectKBest using training data\n",
    "X_train_45 = best_features_selector.fit_transform(X_train_45f, y_train45f)\n",
    "\n",
    "# Displaying selected features\n",
    "selected_feature_indices = best_features_selector.get_support(indices=True)\n",
    "selected_features = X.columns[selected_feature_indices]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Stacking-45features / Imbalanced data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     41732\n",
      "           1       0.88      0.72      0.79      2405\n",
      "\n",
      "    accuracy                           0.98     44137\n",
      "   macro avg       0.93      0.86      0.89     44137\n",
      "weighted avg       0.98      0.98      0.98     44137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train45 = X_train_45\n",
    "X_test45 = X_test_45f[['account_age_days', 'transaction_amt', 'transaction_adj_amt',\n",
    "       'historic_velocity', 'inital_amount', 'month', 'hour', 'day_of_week',\n",
    "       'black_list', 'currency_cad', 'currency_eur', 'currency_usd',\n",
    "       'billing_city_1', 'billing_city_6', 'billing_city_10',\n",
    "       'billing_city_11', 'billing_city_12', 'billing_state_0',\n",
    "       'billing_state_1', 'billing_state_2', 'billing_state_4',\n",
    "       'signature_image_0', 'signature_image_1', 'signature_image_2',\n",
    "       'signature_image_4', 'transaction_type_0', 'transaction_type_1',\n",
    "       'transaction_type_2', 'transaction_type_3', 'transaction_type_4',\n",
    "       'transaction_env_0', 'transaction_env_1', 'transaction_env_2',\n",
    "       'transaction_env_3', 'transaction_env_4', 'tranaction_initiate_1',\n",
    "       'tranaction_initiate_4', 'ip_country_1', 'ip_country_7',\n",
    "       'locale_country_0', 'locale_country_1', 'locale_country_2',\n",
    "       'locale_country_4', 'locale_country_5', 'locale_country_7']]\n",
    "# normalize the data using minmaxscaler\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train45)\n",
    "X_train_sc45 = scaler.transform(X_train45)\n",
    "X_test_sc45 = scaler.transform(X_test45)\n",
    "\n",
    "clf.fit(X_train_sc45, y_train45f)\n",
    "y_test_pred_clf45 = clf.predict(X_test_sc45)\n",
    "y_train_pred_clf45 = clf.predict(X_train_sc45)\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test45f, y_test_pred_clf45)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Training Score  \\\n",
       "0               LogisticRegression / Imbalanced data        0.969423   \n",
       "1  Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                         Stacking / Imbalanced data        0.980939   \n",
       "3              Stacking-45features / Imbalanced data        0.508322   \n",
       "\n",
       "   Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0       0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1       0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2       0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3       0.504883  0.979246  0.978226   0.881208  0.715593  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, clf, X_train45, X_test45, y_train45f, y_test45f, y_train_pred_clf45, y_test_pred_clf45, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to train the model on all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Stacking-all_features / Imbalanced data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     41732\n",
      "           1       0.88      0.73      0.80      2405\n",
      "\n",
      "    accuracy                           0.98     44137\n",
      "   macro avg       0.93      0.86      0.89     44137\n",
      "weighted avg       0.98      0.98      0.98     44137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X, y, stratify=y, random_state=42, test_size=0.3)\n",
    "# normalize the data using minmaxscaler\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train_all)\n",
    "X_train_sc_all = scaler.transform(X_train_all)\n",
    "X_test_sc_all = scaler.transform(X_test_all)\n",
    "\n",
    "clf.fit(X_train_sc_all, y_train_all)\n",
    "y_pred_clf_all = clf.predict(X_test_sc_all)\n",
    "y_train_pred_clf_all = clf.predict(X_train_sc_all)\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_all, y_pred_clf_all)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but GradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Training Score  \\\n",
       "0               LogisticRegression / Imbalanced data        0.969423   \n",
       "1  Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                         Stacking / Imbalanced data        0.980939   \n",
       "3              Stacking-45features / Imbalanced data        0.508322   \n",
       "4            Stacking-all_features / Imbalanced data        0.525547   \n",
       "\n",
       "   Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0       0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1       0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2       0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3       0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4       0.521173  0.979700  0.978842   0.875186  0.731809  "
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, clf, X_train_all, X_test_all, y_train_all, y_test_all, y_train_pred_clf_all, y_pred_clf_all, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random_forest/GridSearch_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Random_forest/GridSearch_all_features / Imbalanced data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     41732\n",
      "           1       0.95      0.45      0.61      2405\n",
      "\n",
      "    accuracy                           0.97     44137\n",
      "   macro avg       0.96      0.73      0.80     44137\n",
      "weighted avg       0.97      0.97      0.96     44137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
    "              'min_samples_leaf': [5],\n",
    "              'max_depth': list(np.linspace(20, 40, 5, dtype=int)),\n",
    "              'criterion' : ['gini', 'entropy']\n",
    "              }\n",
    "\n",
    "\n",
    "grid_search_rf_all = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='recall'\n",
    ")\n",
    "\n",
    "best_params_rf_all = grid_search_rf_all.fit(X_train_all, y_train_all)\n",
    "\n",
    "y_train_pred_rf_all = best_params_rf_all.best_estimator_.predict(X_train_all)\n",
    "y_test_pred_rf_all = best_params_rf_all.best_estimator_.predict(X_test_all)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_all, y_test_pred_rf_all)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Training Score  \\\n",
       "0               LogisticRegression / Imbalanced data        0.969423   \n",
       "1  Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                         Stacking / Imbalanced data        0.980939   \n",
       "3              Stacking-45features / Imbalanced data        0.508322   \n",
       "4            Stacking-all_features / Imbalanced data        0.525547   \n",
       "5  Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "\n",
       "   Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0       0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1       0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2       0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3       0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4       0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5       0.453638  0.969028  0.963756   0.953671  0.453638  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, grid_search_rf_all, X_train_all, X_test_all, y_train_all, y_test_all, y_train_pred_rf_all, y_test_pred_rf_all, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Under Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5610\n",
       "1    5610\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Under Sampling data implimentation\n",
    "random_under_sampler = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = random_under_sampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "y_rus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4208\n",
       "0    4207\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-Test splitting\n",
    "X_train_u_sampled, X_test_u_sampled, y_train_u_sampled, y_test_u_sampled = train_test_split(X_rus, y_rus, test_size=0.25, random_state=42, stratify=y_rus)\n",
    "y_train_u_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      1403\n",
      "           1       0.88      0.87      0.87      1402\n",
      "\n",
      "    accuracy                           0.87      2805\n",
      "   macro avg       0.87      0.87      0.87      2805\n",
      "weighted avg       0.87      0.87      0.87      2805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model with random under sampled data\n",
    "model_name = 'LogisticRegression / Random Under Sampled data'\n",
    "lr = linear_model.LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "lr_model_u_sampled = lr.fit(X_train_u_sampled, y_train_u_sampled)\n",
    "y_train_pred = lr_model_u_sampled.predict(X_train_u_sampled)\n",
    "y_test_pred = lr_model_u_sampled.predict(X_test_u_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_u_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Training Score  \\\n",
       "0               LogisticRegression / Imbalanced data        0.969423   \n",
       "1  Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                         Stacking / Imbalanced data        0.980939   \n",
       "3              Stacking-45features / Imbalanced data        0.508322   \n",
       "4            Stacking-all_features / Imbalanced data        0.525547   \n",
       "5  Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6     LogisticRegression / Random Under Sampled data        0.884492   \n",
       "\n",
       "   Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0       0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1       0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2       0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3       0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4       0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5       0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6       0.872727  0.872727  0.872724   0.876170  0.868046  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, lr, X_train_u_sampled, X_test_u_sampled, y_train_u_sampled, y_test_u_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Over Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97376\n",
       "1    97376\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_over_sampler = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = random_over_sampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "y_ros.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73032\n",
       "1    73032\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-Test splitting\n",
    "X_train_o_sampled, X_test_o_sampled, y_train_o_sampled, y_test_o_sampled = train_test_split(X_ros, y_ros, test_size=0.25, random_state=42, stratify=y_ros)\n",
    "y_train_o_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88     24344\n",
      "           1       0.88      0.88      0.88     24344\n",
      "\n",
      "    accuracy                           0.88     48688\n",
      "   macro avg       0.88      0.88      0.88     48688\n",
      "weighted avg       0.88      0.88      0.88     48688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model with random over sampled data\n",
    "model_name = 'LogisticRegression / Random Over Sampled data'\n",
    "lr = linear_model.LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "lr_model_o_sampled = lr.fit(X_train_o_sampled, y_train_o_sampled)\n",
    "y_train_pred = lr_model_o_sampled.predict(X_train_o_sampled)\n",
    "y_test_pred = lr_model_o_sampled.predict(X_test_o_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_o_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Training Score  \\\n",
       "0               LogisticRegression / Imbalanced data        0.969423   \n",
       "1  Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                         Stacking / Imbalanced data        0.980939   \n",
       "3              Stacking-45features / Imbalanced data        0.508322   \n",
       "4            Stacking-all_features / Imbalanced data        0.525547   \n",
       "5  Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6     LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7      LogisticRegression / Random Over Sampled data        0.883325   \n",
       "\n",
       "   Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0       0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1       0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2       0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3       0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4       0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5       0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6       0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7       0.884345  0.884345  0.884345   0.884298  0.884407  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, lr, X_train_o_sampled, X_test_o_sampled, y_train_o_sampled, y_test_o_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE Over Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    97376\n",
       "1    97376\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_sampler = SMOTE(random_state=42)\n",
    "X_sm, y_sm = smote_sampler.fit_resample(X_train_scaled.astype('float'), y_train)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    73032\n",
       "1    73032\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s_sampled, X_test_s_sampled, y_train_s_sampled, y_test_s_sampled = train_test_split(X_sm, y_sm, test_size=0.25, random_state=42, stratify=y_sm)\n",
    "y_train_s_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     24344\n",
      "           1       0.90      0.90      0.90     24344\n",
      "\n",
      "    accuracy                           0.90     48688\n",
      "   macro avg       0.90      0.90      0.90     48688\n",
      "weighted avg       0.90      0.90      0.90     48688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model with SMOTE over sampled data\n",
    "model_name = 'LogisticRegression / SMOTE Over Sampled data'\n",
    "lr = linear_model.LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "lr_model_s_sampled = lr.fit(X_train_s_sampled, y_train_s_sampled)\n",
    "y_train_pred = lr_model_s_sampled.predict(X_train_s_sampled)\n",
    "y_test_pred = lr_model_s_sampled.predict(X_test_s_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_s_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Training Score  \\\n",
       "0               LogisticRegression / Imbalanced data        0.969423   \n",
       "1  Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                         Stacking / Imbalanced data        0.980939   \n",
       "3              Stacking-45features / Imbalanced data        0.508322   \n",
       "4            Stacking-all_features / Imbalanced data        0.525547   \n",
       "5  Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6     LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7      LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8       LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "\n",
       "   Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0       0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1       0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2       0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3       0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4       0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5       0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6       0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7       0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8       0.900058  0.900058  0.900057   0.898063  0.902563  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, lr, X_train_s_sampled, X_test_s_sampled, y_train_s_sampled, y_test_s_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Under Sampling data with optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/admin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      1403\n",
      "           1       0.87      0.87      0.87      1402\n",
      "\n",
      "    accuracy                           0.87      2805\n",
      "   macro avg       0.87      0.87      0.87      2805\n",
      "weighted avg       0.87      0.87      0.87      2805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preparing Grid Search \n",
    "param_grid = [\n",
    "              {'penalty': ['l2', 'none'], \n",
    "              'solver': ['lbfgs', 'sag'],\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]},\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "]\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=1000), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs=-1,\n",
    "    scoring='recall'\n",
    ")\n",
    "\n",
    "model_name = 'Tuned LogisticRegression / Random Under Sampled data'\n",
    "best_params_lr = grid_search_lr.fit(X_train_u_sampled, y_train_u_sampled)\n",
    "\n",
    "y_train_pred = best_params_lr.best_estimator_.predict(X_train_u_sampled)\n",
    "y_test_pred = best_params_lr.best_estimator_.predict(X_test_u_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_u_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Training Score  \\\n",
       "0               LogisticRegression / Imbalanced data        0.969423   \n",
       "1  Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                         Stacking / Imbalanced data        0.980939   \n",
       "3              Stacking-45features / Imbalanced data        0.508322   \n",
       "4            Stacking-all_features / Imbalanced data        0.525547   \n",
       "5  Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6     LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7      LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8       LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9  Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "\n",
       "   Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0       0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1       0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2       0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3       0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4       0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5       0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6       0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7       0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8       0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9       0.871658  0.871658  0.871657   0.873745  0.868759  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, best_params_lr.best_estimator_, X_train_u_sampled, X_test_u_sampled, y_train_u_sampled, y_test_u_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree - Random Under Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1403\n",
      "           1       0.89      0.84      0.86      1402\n",
      "\n",
      "    accuracy                           0.87      2805\n",
      "   macro avg       0.87      0.87      0.87      2805\n",
      "weighted avg       0.87      0.87      0.87      2805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model with Random Under Sampled data\n",
    "model_name = 'DecisionTreeClassifier / Random Under Sampled data'\n",
    "dt = tree.DecisionTreeClassifier(\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model_u_sampled = dt.fit(X_train_u_sampled, y_train_u_sampled)\n",
    "y_train_pred = dt_model_u_sampled.predict(X_train_u_sampled)\n",
    "y_test_pred = dt_model_u_sampled.predict(X_test_u_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_u_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, dt, X_train_u_sampled, X_test_u_sampled, y_train_u_sampled, y_test_u_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree - Random Over Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     24344\n",
      "           1       0.92      0.90      0.91     24344\n",
      "\n",
      "    accuracy                           0.91     48688\n",
      "   macro avg       0.91      0.91      0.91     48688\n",
      "weighted avg       0.91      0.91      0.91     48688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model with Random Over Sampled data\n",
    "model_name = 'DecisionTreeClassifier / Random Over Sampled data'\n",
    "dt = tree.DecisionTreeClassifier(\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model_o_sampled = dt.fit(X_train_o_sampled, y_train_o_sampled)\n",
    "y_train_pred = dt_model_o_sampled.predict(X_train_o_sampled)\n",
    "y_test_pred = dt_model_o_sampled.predict(X_test_o_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_o_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, dt, X_train_o_sampled, X_test_o_sampled, y_train_o_sampled, y_test_o_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree - SMOTE Over Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     24344\n",
      "           1       0.95      0.93      0.94     24344\n",
      "\n",
      "    accuracy                           0.94     48688\n",
      "   macro avg       0.94      0.94      0.94     48688\n",
      "weighted avg       0.94      0.94      0.94     48688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model with SMOTE Over Sampled data\n",
    "model_name = 'DecisionTreeClassifier / SMOTE Over Sampled data'\n",
    "dt = tree.DecisionTreeClassifier(\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model_s_sampled = dt.fit(X_train_s_sampled, y_train_s_sampled)\n",
    "y_train_pred = dt_model_s_sampled.predict(X_train_s_sampled)\n",
    "y_test_pred = dt_model_s_sampled.predict(X_test_s_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_s_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, dt, X_train_s_sampled, X_test_s_sampled, y_train_s_sampled, y_test_s_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree - Imbala Random Under sampled data - Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, min_samples_leaf=2, random_state=42)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max depth of tree\n",
    "max_depth = list(np.linspace(start=4, stop=20, num=5, dtype=int))\n",
    "# Number of samples to split a node\n",
    "min_samples_split = list(np.linspace(start=2, stop=12, num=6, dtype=int))\n",
    "# Number of samplet at leaf node\n",
    "min_samples_leaf = list(np.linspace(start=2, stop=12, num=6, dtype=int))\n",
    "# Type of criterion\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Preparing Grid Search\n",
    "param_grid = {\n",
    "    'max_depth':max_depth,\n",
    "    'min_samples_leaf':min_samples_leaf,\n",
    "    'min_samples_split':min_samples_split,\n",
    "    'criterion':criterion\n",
    "}\n",
    "\n",
    "grid_search_tree = GridSearchCV(\n",
    "    estimator=tree.DecisionTreeClassifier(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs=-1,\n",
    "    scoring='recall'\n",
    ")\n",
    "\n",
    "model_name = 'Tuned DecisionTreeClassifier / Random Under sampled data'\n",
    "best_params_dt = grid_search_tree.fit(X_train_u_sampled, y_train_u_sampled)\n",
    "\n",
    "y_train_pred = best_params_dt.best_estimator_.predict(X_train_u_sampled)\n",
    "y_test_pred = best_params_dt.best_estimator_.predict(X_test_u_sampled)\n",
    "best_params_dt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      1403\n",
      "           1       0.87      0.86      0.86      1402\n",
      "\n",
      "    accuracy                           0.87      2805\n",
      "   macro avg       0.87      0.87      0.87      2805\n",
      "weighted avg       0.87      0.87      0.87      2805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_u_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuned DecisionTreeClassifier / Random Under sa...</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.871014</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "13  Tuned DecisionTreeClassifier / Random Under sa...        0.881521   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  \n",
       "13       0.865241  0.865241  0.865232   0.871014  0.857347  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, best_params_dt.best_estimator_, X_train_u_sampled, X_test_u_sampled, y_train_u_sampled, y_test_u_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     41732\n",
      "           1       0.91      0.51      0.66      2405\n",
      "\n",
      "    accuracy                           0.97     44137\n",
      "   macro avg       0.94      0.76      0.82     44137\n",
      "weighted avg       0.97      0.97      0.97     44137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model with imbalanced data\n",
    "model_name = 'RandomForestClassifier / Imbalanced data'\n",
    "rf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model = rf.fit(X_train_scaled, y_train)\n",
    "y_train_pred = rf_model.predict(X_train_scaled)\n",
    "y_test_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuned DecisionTreeClassifier / Random Under sa...</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.871014</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier / Imbalanced data</td>\n",
       "      <td>0.973443</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.513929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "13  Tuned DecisionTreeClassifier / Random Under sa...        0.881521   \n",
       "14           RandomForestClassifier / Imbalanced data        0.973443   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  \n",
       "13       0.865241  0.865241  0.865232   0.871014  0.857347  \n",
       "14       0.970818  0.970818  0.966925   0.912177  0.513929  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, rf, X_train_scaled, X_test_scaled, y_train, y_test, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Random Under Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      1403\n",
      "           1       0.91      0.86      0.89      1402\n",
      "\n",
      "    accuracy                           0.89      2805\n",
      "   macro avg       0.89      0.89      0.89      2805\n",
      "weighted avg       0.89      0.89      0.89      2805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model with Random Under Sampling data\n",
    "model_name = 'RandomForestClassifier / Random Under Sampling data'\n",
    "rf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_u_model = rf.fit(X_train_u_sampled, y_train_u_sampled)\n",
    "y_train_pred = rf_u_model.predict(X_train_u_sampled)\n",
    "y_test_pred = rf_u_model.predict(X_test_u_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_u_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuned DecisionTreeClassifier / Random Under sa...</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.871014</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier / Imbalanced data</td>\n",
       "      <td>0.973443</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.513929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier / Random Under Sampling...</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.909159</td>\n",
       "      <td>0.863766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "13  Tuned DecisionTreeClassifier / Random Under sa...        0.881521   \n",
       "14           RandomForestClassifier / Imbalanced data        0.973443   \n",
       "15  RandomForestClassifier / Random Under Sampling...        0.936067   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  \n",
       "13       0.865241  0.865241  0.865232   0.871014  0.857347  \n",
       "14       0.970818  0.970818  0.966925   0.912177  0.513929  \n",
       "15       0.888770  0.888770  0.888700   0.909159  0.863766  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, rf, X_train_u_sampled, X_test_u_sampled, y_train_u_sampled, y_test_u_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Random Over Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     24344\n",
      "           1       0.93      0.90      0.92     24344\n",
      "\n",
      "    accuracy                           0.92     48688\n",
      "   macro avg       0.92      0.92      0.92     48688\n",
      "weighted avg       0.92      0.92      0.92     48688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model with Random Over Sampling data\n",
    "model_name = 'RandomForestClassifier / Random Over Sampling data'\n",
    "rf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_o_model = rf.fit(X_train_o_sampled, y_train_o_sampled)\n",
    "y_train_pred = rf_o_model.predict(X_train_o_sampled)\n",
    "y_test_pred = rf_o_model.predict(X_test_o_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_o_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuned DecisionTreeClassifier / Random Under sa...</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.871014</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier / Imbalanced data</td>\n",
       "      <td>0.973443</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.513929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier / Random Under Sampling...</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.909159</td>\n",
       "      <td>0.863766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier / Random Over Sampling ...</td>\n",
       "      <td>0.918495</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.930249</td>\n",
       "      <td>0.902851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "13  Tuned DecisionTreeClassifier / Random Under sa...        0.881521   \n",
       "14           RandomForestClassifier / Imbalanced data        0.973443   \n",
       "15  RandomForestClassifier / Random Under Sampling...        0.936067   \n",
       "16  RandomForestClassifier / Random Over Sampling ...        0.918495   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  \n",
       "13       0.865241  0.865241  0.865232   0.871014  0.857347  \n",
       "14       0.970818  0.970818  0.966925   0.912177  0.513929  \n",
       "15       0.888770  0.888770  0.888700   0.909159  0.863766  \n",
       "16       0.917577  0.917577  0.917559   0.930249  0.902851  "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, rf, X_train_o_sampled, X_test_o_sampled, y_train_o_sampled, y_test_o_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - SMOTE Over Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     24344\n",
      "           1       0.94      0.94      0.94     24344\n",
      "\n",
      "    accuracy                           0.94     48688\n",
      "   macro avg       0.94      0.94      0.94     48688\n",
      "weighted avg       0.94      0.94      0.94     48688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model with Random Over Sampling data\n",
    "model_name = 'RandomForestClassifier / SMOTE Over Sampling data'\n",
    "rf = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_s_model = rf.fit(X_train_s_sampled, y_train_s_sampled)\n",
    "y_train_pred = rf_s_model.predict(X_train_s_sampled)\n",
    "y_test_pred = rf_s_model.predict(X_test_s_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_s_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7570133 , 0.52519528, 0.56393208, 0.55820649, 0.06329663,\n",
       "       0.50592782, 1.        , 1.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.85869849, 0.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_s_sampled[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuned DecisionTreeClassifier / Random Under sa...</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.871014</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier / Imbalanced data</td>\n",
       "      <td>0.973443</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.513929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier / Random Under Sampling...</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.909159</td>\n",
       "      <td>0.863766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier / Random Over Sampling ...</td>\n",
       "      <td>0.918495</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.930249</td>\n",
       "      <td>0.902851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier / SMOTE Over Sampling data</td>\n",
       "      <td>0.943648</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.939446</td>\n",
       "      <td>0.936822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "13  Tuned DecisionTreeClassifier / Random Under sa...        0.881521   \n",
       "14           RandomForestClassifier / Imbalanced data        0.973443   \n",
       "15  RandomForestClassifier / Random Under Sampling...        0.936067   \n",
       "16  RandomForestClassifier / Random Over Sampling ...        0.918495   \n",
       "17  RandomForestClassifier / SMOTE Over Sampling data        0.943648   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  \n",
       "13       0.865241  0.865241  0.865232   0.871014  0.857347  \n",
       "14       0.970818  0.970818  0.966925   0.912177  0.513929  \n",
       "15       0.888770  0.888770  0.888700   0.909159  0.863766  \n",
       "16       0.917577  0.917577  0.917559   0.930249  0.902851  \n",
       "17       0.938219  0.938219  0.938219   0.939446  0.936822  "
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, rf, X_train_s_sampled, X_test_s_sampled, y_train_s_sampled, y_test_s_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Random Under Sampling data - Tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in Random Forest\n",
    "n_estimators = list(np.linspace(start=100, stop=300, num=5, dtype=int))\n",
    "# Max depth of trees in Random Forest\n",
    "max_depth = list(np.linspace(start=4, stop=20, num=5, dtype=int))\n",
    "# Number of samples to split a node\n",
    "min_samples_split = list(np.linspace(start=2, stop=12, num=6, dtype=int))\n",
    "# Number of samplet at leaf node\n",
    "min_samples_leaf = list(np.linspace(start=2, stop=12, num=6, dtype=int))\n",
    "# Type of criterion\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators':n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'min_samples_leaf':min_samples_leaf,\n",
    "    'min_samples_split':min_samples_split,\n",
    "    'criterion':criterion\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the test sample: \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      1403\n",
      "           1       0.91      0.86      0.89      1402\n",
      "\n",
      "    accuracy                           0.89      2805\n",
      "   macro avg       0.89      0.89      0.89      2805\n",
      "weighted avg       0.89      0.89      0.89      2805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='recall'\n",
    ")\n",
    "\n",
    "\n",
    "model_name = 'Tuned RandomForestClassifier / Random Under Sampled data'\n",
    "best_params_rf = grid_search_rf.fit(X_train_u_sampled, y_train_u_sampled)\n",
    "\n",
    "y_train_pred = best_params_rf.best_estimator_.predict(X_train_u_sampled)\n",
    "y_test_pred = best_params_rf.best_estimator_.predict(X_test_u_sampled)\n",
    "\n",
    "print(f'Metrics for the test sample: \\n \\n{metrics.classification_report(y_test_u_sampled, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuned DecisionTreeClassifier / Random Under sa...</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.871014</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier / Imbalanced data</td>\n",
       "      <td>0.973443</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.513929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier / Random Under Sampling...</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.909159</td>\n",
       "      <td>0.863766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier / Random Over Sampling ...</td>\n",
       "      <td>0.918495</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.930249</td>\n",
       "      <td>0.902851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier / SMOTE Over Sampling data</td>\n",
       "      <td>0.943648</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.939446</td>\n",
       "      <td>0.936822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tuned RandomForestClassifier / Random Under Sa...</td>\n",
       "      <td>0.941414</td>\n",
       "      <td>0.888414</td>\n",
       "      <td>0.888414</td>\n",
       "      <td>0.888349</td>\n",
       "      <td>0.907865</td>\n",
       "      <td>0.864479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "13  Tuned DecisionTreeClassifier / Random Under sa...        0.881521   \n",
       "14           RandomForestClassifier / Imbalanced data        0.973443   \n",
       "15  RandomForestClassifier / Random Under Sampling...        0.936067   \n",
       "16  RandomForestClassifier / Random Over Sampling ...        0.918495   \n",
       "17  RandomForestClassifier / SMOTE Over Sampling data        0.943648   \n",
       "18  Tuned RandomForestClassifier / Random Under Sa...        0.941414   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  \n",
       "13       0.865241  0.865241  0.865232   0.871014  0.857347  \n",
       "14       0.970818  0.970818  0.966925   0.912177  0.513929  \n",
       "15       0.888770  0.888770  0.888700   0.909159  0.863766  \n",
       "16       0.917577  0.917577  0.917559   0.930249  0.902851  \n",
       "17       0.938219  0.938219  0.938219   0.939446  0.936822  \n",
       "18       0.888414  0.888414  0.888349   0.907865  0.864479  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding baseline model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, best_params_rf.best_estimator_, X_train_u_sampled, X_test_u_sampled, y_train_u_sampled, y_test_u_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The first is the processing of addresses; you also need to add signs of correspondence between the country in which the payment was made and the country of account registration\n",
    "it is necessary to work with the ip addresses attribute\n",
    "Also a sign of user_agent - you need to drag in both the domain and the browser and see from which browser transactions are usually made.__\n",
    "\n",
    "Then try using gridsearch to sort through the parameters and make a complex model. But all this will give results if you follow step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ,      ,       .\n",
    "    ip adres\n",
    "  user_agent -              .\n",
    "\n",
    "    gridsearch      .     ,    1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost - Random Under Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset\n",
    "pool = Pool(data=X_train_u_sampled, label=y_train_u_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation Logloss score, stratified: 0.2286+/-0.014 on step 94\n"
     ]
    }
   ],
   "source": [
    "# cv\n",
    "params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'iterations': 300,\n",
    "    'custom_loss': 'Recall',\n",
    "    'random_seed': 42,\n",
    "    'learning_rate': 0.15\n",
    "}\n",
    "\n",
    "cv_data = cv(\n",
    "    params=params,\n",
    "    pool=Pool(data=X_train_u_sampled, label=y_train_u_sampled),\n",
    "    fold_count=5, # separating to 5 folds\n",
    "    shuffle=True,\n",
    "    partition_random_seed=42,\n",
    "    stratified=True, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Best score printing\n",
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = np.argmin(cv_data['test-Logloss-mean'])\n",
    "print(\"Best validation Logloss score, stratified: {:.4f}+/-{:.3f} on step {}\".format(best_value, cv_data['test-Logloss-std'][best_iter], best_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7799430\ttest: 0.7646570\tbest: 0.7646570 (0)\ttotal: 10.4ms\tremaining: 3.11s\n",
      "50:\tlearn: 0.9073194\ttest: 0.8918919\tbest: 0.8918919 (50)\ttotal: 1.04s\tremaining: 5.07s\n",
      "100:\tlearn: 0.9230038\ttest: 0.8923077\tbest: 0.8948025 (88)\ttotal: 2.29s\tremaining: 4.51s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.8948024948\n",
      "bestIteration = 88\n",
      "\n",
      "Shrink model to first 89 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Creating model object\n",
    "cb_model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    learning_rate=0.15,\n",
    "    eval_metric='Recall'\n",
    ")\n",
    "\n",
    "model_name = 'CatBoostClassifier / Random Under Sampled data'\n",
    "cb_model.fit(X_train_u_sampled, y_train_u_sampled,\n",
    "         eval_set=(X_test_scaled, y_test),\n",
    "         verbose=50,\n",
    "         early_stopping_rounds=20,\n",
    ")\n",
    "\n",
    "y_train_pred = cb_model.predict(X_train_u_sampled)\n",
    "y_test_pred = cb_model.predict(X_test_u_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuned DecisionTreeClassifier / Random Under sa...</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.871014</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier / Imbalanced data</td>\n",
       "      <td>0.973443</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.513929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier / Random Under Sampling...</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.909159</td>\n",
       "      <td>0.863766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier / Random Over Sampling ...</td>\n",
       "      <td>0.918495</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.930249</td>\n",
       "      <td>0.902851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier / SMOTE Over Sampling data</td>\n",
       "      <td>0.943648</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.939446</td>\n",
       "      <td>0.936822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tuned RandomForestClassifier / Random Under Sa...</td>\n",
       "      <td>0.941414</td>\n",
       "      <td>0.888414</td>\n",
       "      <td>0.888414</td>\n",
       "      <td>0.888349</td>\n",
       "      <td>0.907865</td>\n",
       "      <td>0.864479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CatBoostClassifier / Random Under Sampled data</td>\n",
       "      <td>0.934759</td>\n",
       "      <td>0.895544</td>\n",
       "      <td>0.895544</td>\n",
       "      <td>0.895493</td>\n",
       "      <td>0.913497</td>\n",
       "      <td>0.873752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "13  Tuned DecisionTreeClassifier / Random Under sa...        0.881521   \n",
       "14           RandomForestClassifier / Imbalanced data        0.973443   \n",
       "15  RandomForestClassifier / Random Under Sampling...        0.936067   \n",
       "16  RandomForestClassifier / Random Over Sampling ...        0.918495   \n",
       "17  RandomForestClassifier / SMOTE Over Sampling data        0.943648   \n",
       "18  Tuned RandomForestClassifier / Random Under Sa...        0.941414   \n",
       "19     CatBoostClassifier / Random Under Sampled data        0.934759   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  \n",
       "13       0.865241  0.865241  0.865232   0.871014  0.857347  \n",
       "14       0.970818  0.970818  0.966925   0.912177  0.513929  \n",
       "15       0.888770  0.888770  0.888700   0.909159  0.863766  \n",
       "16       0.917577  0.917577  0.917559   0.930249  0.902851  \n",
       "17       0.938219  0.938219  0.938219   0.939446  0.936822  \n",
       "18       0.888414  0.888414  0.888349   0.907865  0.864479  \n",
       "19       0.895544  0.895544  0.895493   0.913497  0.873752  "
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, cb_model, X_train_u_sampled, X_test_u_sampled, y_train_u_sampled, y_test_u_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost - Random Over Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset\n",
    "pool = Pool(data=X_train_o_sampled, label=y_train_o_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation Logloss score, stratified: 0.1320+/-0.002 on step 299\n"
     ]
    }
   ],
   "source": [
    "# cv\n",
    "params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'iterations': 300,\n",
    "    'custom_loss': 'Recall',\n",
    "    'random_seed': 42,\n",
    "    'learning_rate': 0.15\n",
    "}\n",
    "\n",
    "cv_data = cv(\n",
    "    params=params,\n",
    "    pool=Pool(data=X_train_o_sampled, label=y_train_o_sampled),\n",
    "    fold_count=5, # separating to 5 folds\n",
    "    shuffle=True,\n",
    "    partition_random_seed=42,\n",
    "    stratified=True, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Best score printing\n",
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = np.argmin(cv_data['test-Logloss-mean'])\n",
    "print(\"Best validation Logloss score, stratified: {:.4f}+/-{:.3f} on step {}\".format(best_value, cv_data['test-Logloss-std'][best_iter], best_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8607734\ttest: 0.8665281\tbest: 0.8665281 (0)\ttotal: 156ms\tremaining: 46.5s\n",
      "50:\tlearn: 0.8990716\ttest: 0.8881497\tbest: 0.8910603 (39)\ttotal: 8.44s\tremaining: 41.2s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.8910602911\n",
      "bestIteration = 39\n",
      "\n",
      "Shrink model to first 40 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Creating model object\n",
    "cb_o_model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    learning_rate=0.15,\n",
    "    eval_metric='Recall'\n",
    ")\n",
    "\n",
    "model_name = 'CatBoostClassifier / Random Over Sampled data'\n",
    "cb_o_model.fit(X_train_o_sampled, y_train_o_sampled,\n",
    "         eval_set=(X_test_scaled, y_test),\n",
    "         verbose=50,\n",
    "         early_stopping_rounds=20,\n",
    ")\n",
    "\n",
    "y_train_pred = cb_o_model.predict(X_train_o_sampled)\n",
    "y_test_pred = cb_o_model.predict(X_test_o_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuned DecisionTreeClassifier / Random Under sa...</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.871014</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier / Imbalanced data</td>\n",
       "      <td>0.973443</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.513929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier / Random Under Sampling...</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.909159</td>\n",
       "      <td>0.863766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier / Random Over Sampling ...</td>\n",
       "      <td>0.918495</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.930249</td>\n",
       "      <td>0.902851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier / SMOTE Over Sampling data</td>\n",
       "      <td>0.943648</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.939446</td>\n",
       "      <td>0.936822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tuned RandomForestClassifier / Random Under Sa...</td>\n",
       "      <td>0.941414</td>\n",
       "      <td>0.888414</td>\n",
       "      <td>0.888414</td>\n",
       "      <td>0.888349</td>\n",
       "      <td>0.907865</td>\n",
       "      <td>0.864479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CatBoostClassifier / Random Under Sampled data</td>\n",
       "      <td>0.934759</td>\n",
       "      <td>0.895544</td>\n",
       "      <td>0.895544</td>\n",
       "      <td>0.895493</td>\n",
       "      <td>0.913497</td>\n",
       "      <td>0.873752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CatBoostClassifier / Random Over Sampled data</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.909341</td>\n",
       "      <td>0.909341</td>\n",
       "      <td>0.909331</td>\n",
       "      <td>0.918241</td>\n",
       "      <td>0.898702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "13  Tuned DecisionTreeClassifier / Random Under sa...        0.881521   \n",
       "14           RandomForestClassifier / Imbalanced data        0.973443   \n",
       "15  RandomForestClassifier / Random Under Sampling...        0.936067   \n",
       "16  RandomForestClassifier / Random Over Sampling ...        0.918495   \n",
       "17  RandomForestClassifier / SMOTE Over Sampling data        0.943648   \n",
       "18  Tuned RandomForestClassifier / Random Under Sa...        0.941414   \n",
       "19     CatBoostClassifier / Random Under Sampled data        0.934759   \n",
       "20      CatBoostClassifier / Random Over Sampled data        0.909601   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  \n",
       "13       0.865241  0.865241  0.865232   0.871014  0.857347  \n",
       "14       0.970818  0.970818  0.966925   0.912177  0.513929  \n",
       "15       0.888770  0.888770  0.888700   0.909159  0.863766  \n",
       "16       0.917577  0.917577  0.917559   0.930249  0.902851  \n",
       "17       0.938219  0.938219  0.938219   0.939446  0.936822  \n",
       "18       0.888414  0.888414  0.888349   0.907865  0.864479  \n",
       "19       0.895544  0.895544  0.895493   0.913497  0.873752  \n",
       "20       0.909341  0.909341  0.909331   0.918241  0.898702  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, cb_o_model, X_train_o_sampled, X_test_o_sampled, y_train_o_sampled, y_test_o_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost - SMOTE Over Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset\n",
    "pool = Pool(data=X_train_s_sampled, label=y_train_s_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation Logloss score, stratified: 0.0409+/-0.001 on step 299\n"
     ]
    }
   ],
   "source": [
    "# cv\n",
    "params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'iterations': 300,\n",
    "    'custom_loss': 'Recall',\n",
    "    'random_seed': 42,\n",
    "    'learning_rate': 0.15\n",
    "}\n",
    "\n",
    "cv_data = cv(\n",
    "    params=params,\n",
    "    pool=Pool(data=X_train_s_sampled, label=y_train_s_sampled),\n",
    "    fold_count=5, # separating to 5 folds\n",
    "    shuffle=True,\n",
    "    partition_random_seed=42,\n",
    "    stratified=True, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Best score printing\n",
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = np.argmin(cv_data['test-Logloss-mean'])\n",
    "print(\"Best validation Logloss score, stratified: {:.4f}+/-{:.3f} on step {}\".format(best_value, cv_data['test-Logloss-std'][best_iter], best_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9092316\ttest: 0.8049896\tbest: 0.8049896 (0)\ttotal: 95.2ms\tremaining: 28.5s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.8486486486\n",
      "bestIteration = 3\n",
      "\n",
      "Shrink model to first 4 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Creating model object\n",
    "cb_s_model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    learning_rate=0.15,\n",
    "    eval_metric='Recall'\n",
    ")\n",
    "\n",
    "model_name = 'CatBoostClassifier / SMOTE Over Sampled data'\n",
    "cb_s_model.fit(X_train_s_sampled, y_train_s_sampled,\n",
    "         eval_set=(X_test_scaled, y_test),\n",
    "         verbose=50,\n",
    "         early_stopping_rounds=20,\n",
    ")\n",
    "\n",
    "y_train_pred = cb_s_model.predict(X_train_s_sampled)\n",
    "y_test_pred = cb_s_model.predict(X_test_s_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/y12hg0bj54sg455fwlths6dw0000gp/T/ipykernel_35359/2868486197.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_evalution_df = model_evalution_df.append(model_evalution_dict, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression / Imbalanced data</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.965576</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>0.548441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline - RandomForestClassifier / Imbalanced...</td>\n",
       "      <td>0.973288</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.899570</td>\n",
       "      <td>0.521414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stacking / Imbalanced data</td>\n",
       "      <td>0.980939</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>0.876596</td>\n",
       "      <td>0.685239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking-45features / Imbalanced data</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.881208</td>\n",
       "      <td>0.715593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stacking-all_features / Imbalanced data</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.521173</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.875186</td>\n",
       "      <td>0.731809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random_forest/GridSearch_all_features / Imbala...</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.453638</td>\n",
       "      <td>0.969028</td>\n",
       "      <td>0.963756</td>\n",
       "      <td>0.953671</td>\n",
       "      <td>0.453638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression / Random Under Sampled data</td>\n",
       "      <td>0.884492</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.872724</td>\n",
       "      <td>0.876170</td>\n",
       "      <td>0.868046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression / Random Over Sampled data</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884345</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>0.884407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression / SMOTE Over Sampled data</td>\n",
       "      <td>0.901201</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.900057</td>\n",
       "      <td>0.898063</td>\n",
       "      <td>0.902563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuned LogisticRegression / Random Under Sample...</td>\n",
       "      <td>0.883541</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871658</td>\n",
       "      <td>0.871657</td>\n",
       "      <td>0.873745</td>\n",
       "      <td>0.868759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier / Random Under Sampled ...</td>\n",
       "      <td>0.932620</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>0.867664</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.844508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier / Random Over Sampled data</td>\n",
       "      <td>0.910327</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908458</td>\n",
       "      <td>0.908447</td>\n",
       "      <td>0.917566</td>\n",
       "      <td>0.897552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.945428</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.939507</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>0.929551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tuned DecisionTreeClassifier / Random Under sa...</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865241</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.871014</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier / Imbalanced data</td>\n",
       "      <td>0.973443</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.970818</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.912177</td>\n",
       "      <td>0.513929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestClassifier / Random Under Sampling...</td>\n",
       "      <td>0.936067</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.909159</td>\n",
       "      <td>0.863766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomForestClassifier / Random Over Sampling ...</td>\n",
       "      <td>0.918495</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917577</td>\n",
       "      <td>0.917559</td>\n",
       "      <td>0.930249</td>\n",
       "      <td>0.902851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestClassifier / SMOTE Over Sampling data</td>\n",
       "      <td>0.943648</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.938219</td>\n",
       "      <td>0.939446</td>\n",
       "      <td>0.936822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tuned RandomForestClassifier / Random Under Sa...</td>\n",
       "      <td>0.941414</td>\n",
       "      <td>0.888414</td>\n",
       "      <td>0.888414</td>\n",
       "      <td>0.888349</td>\n",
       "      <td>0.907865</td>\n",
       "      <td>0.864479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CatBoostClassifier / Random Under Sampled data</td>\n",
       "      <td>0.934759</td>\n",
       "      <td>0.895544</td>\n",
       "      <td>0.895544</td>\n",
       "      <td>0.895493</td>\n",
       "      <td>0.913497</td>\n",
       "      <td>0.873752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CatBoostClassifier / Random Over Sampled data</td>\n",
       "      <td>0.909601</td>\n",
       "      <td>0.909341</td>\n",
       "      <td>0.909341</td>\n",
       "      <td>0.909331</td>\n",
       "      <td>0.918241</td>\n",
       "      <td>0.898702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CatBoostClassifier / SMOTE Over Sampled data</td>\n",
       "      <td>0.918638</td>\n",
       "      <td>0.916920</td>\n",
       "      <td>0.916920</td>\n",
       "      <td>0.916914</td>\n",
       "      <td>0.909832</td>\n",
       "      <td>0.925567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  Training Score  \\\n",
       "0                LogisticRegression / Imbalanced data        0.969423   \n",
       "1   Baseline - RandomForestClassifier / Imbalanced...        0.973288   \n",
       "2                          Stacking / Imbalanced data        0.980939   \n",
       "3               Stacking-45features / Imbalanced data        0.508322   \n",
       "4             Stacking-all_features / Imbalanced data        0.525547   \n",
       "5   Random_forest/GridSearch_all_features / Imbala...        0.664349   \n",
       "6      LogisticRegression / Random Under Sampled data        0.884492   \n",
       "7       LogisticRegression / Random Over Sampled data        0.883325   \n",
       "8        LogisticRegression / SMOTE Over Sampled data        0.901201   \n",
       "9   Tuned LogisticRegression / Random Under Sample...        0.883541   \n",
       "10  DecisionTreeClassifier / Random Under Sampled ...        0.932620   \n",
       "11  DecisionTreeClassifier / Random Over Sampled data        0.910327   \n",
       "12   DecisionTreeClassifier / SMOTE Over Sampled data        0.945428   \n",
       "13  Tuned DecisionTreeClassifier / Random Under sa...        0.881521   \n",
       "14           RandomForestClassifier / Imbalanced data        0.973443   \n",
       "15  RandomForestClassifier / Random Under Sampling...        0.936067   \n",
       "16  RandomForestClassifier / Random Over Sampling ...        0.918495   \n",
       "17  RandomForestClassifier / SMOTE Over Sampling data        0.943648   \n",
       "18  Tuned RandomForestClassifier / Random Under Sa...        0.941414   \n",
       "19     CatBoostClassifier / Random Under Sampled data        0.934759   \n",
       "20      CatBoostClassifier / Random Over Sampled data        0.909601   \n",
       "21       CatBoostClassifier / SMOTE Over Sampled data        0.918638   \n",
       "\n",
       "    Testing Score  Accuracy  F1 Score  Precision    Recall  \n",
       "0        0.968484  0.968484  0.965576   0.812192  0.548441  \n",
       "1        0.970750  0.970750  0.967033   0.899570  0.521414  \n",
       "2        0.977592  0.977592  0.976290   0.876596  0.685239  \n",
       "3        0.504883  0.979246  0.978226   0.881208  0.715593  \n",
       "4        0.521173  0.979700  0.978842   0.875186  0.731809  \n",
       "5        0.453638  0.969028  0.963756   0.953671  0.453638  \n",
       "6        0.872727  0.872727  0.872724   0.876170  0.868046  \n",
       "7        0.884345  0.884345  0.884345   0.884298  0.884407  \n",
       "8        0.900058  0.900058  0.900057   0.898063  0.902563  \n",
       "9        0.871658  0.871658  0.871657   0.873745  0.868759  \n",
       "10       0.867736  0.867736  0.867664   0.885565  0.844508  \n",
       "11       0.908458  0.908458  0.908447   0.917566  0.897552  \n",
       "12       0.939513  0.939513  0.939507   0.948447  0.929551  \n",
       "13       0.865241  0.865241  0.865232   0.871014  0.857347  \n",
       "14       0.970818  0.970818  0.966925   0.912177  0.513929  \n",
       "15       0.888770  0.888770  0.888700   0.909159  0.863766  \n",
       "16       0.917577  0.917577  0.917559   0.930249  0.902851  \n",
       "17       0.938219  0.938219  0.938219   0.939446  0.936822  \n",
       "18       0.888414  0.888414  0.888349   0.907865  0.864479  \n",
       "19       0.895544  0.895544  0.895493   0.913497  0.873752  \n",
       "20       0.909341  0.909341  0.909331   0.918241  0.898702  \n",
       "21       0.916920  0.916920  0.916914   0.909832  0.925567  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding model evalution statistics\n",
    "model_evalution_df = add_model_evalution_stat(model_name, cb_s_model, X_train_s_sampled, X_test_s_sampled, y_train_s_sampled, y_test_s_sampled, y_train_pred, y_test_pred, model_evalution_df)\n",
    "model_evalution_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving fitted model (RandomForestClassifier / SMOTE Over Sampling data)\n",
    "with open('models/model.pkl', 'wb') as output:\n",
    "    pickle.dump(rf_s_model, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "#### Many models have been built through machine learning. In order to carry out the experiment, logistic regression on different data sets, decision trees, random forest, and CatBoostClassifier were implemented. \n",
    "\n",
    "#### The problem with the training dataset is class imbalance. Three methods were implemented to combat imbalance, which clearly improved the quality of models for all algorithms.\n",
    "\n",
    "#### Thus, the most important aspects were feature selection and combating class imbalance.\n",
    "\n",
    "#### RandomForestClassifier / SMOTE Over Sampling data was chosen as the final model: recall 0.936822, f1 score 0.938219."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __We have quite complex, up-to-date transaction data. The task was to build a machine learning model that predicts fraudulent transactions. Let me summarize the work done, a fairly broad reconnaissance analysis, and we can conclude that it is very difficult to determine dependencies in the data by eye. At the same time, the presence of a large number of observations, data processing and working with class imbalance helped solve the problem with a fairly good result.__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
